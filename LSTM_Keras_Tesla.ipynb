{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Keras_Tesla.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/douglasbarbosadelima/Data-Science/blob/master/LSTM_Keras_Tesla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePVO9pOJ6jgh",
        "colab_type": "text"
      },
      "source": [
        "# LSTM_Keras_Tesla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHL2w9KxTFRg",
        "colab_type": "code",
        "outputId": "94814387-5dc0-474a-f985-718cde07c6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow import set_random_seed\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwilz_qnTIdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "8f7b1ce4-1ee3-47e3-d258-32b7fe70c49f"
      },
      "source": [
        "set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/douglasbarbosadelima/Data-Science/master/tesla-stocks.csv')\n",
        "\n",
        "df = df.drop(columns=['Date', 'High', 'Low', 'Close', 'Volume', 'Adj Close'])\n",
        "\n",
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.790001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687</th>\n",
              "      <td>244.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1688</th>\n",
              "      <td>246.110001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1689</th>\n",
              "      <td>257.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1690</th>\n",
              "      <td>262.399994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1691</th>\n",
              "      <td>264.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1692 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Open\n",
              "0      19.000000\n",
              "1      25.790001\n",
              "2      25.000000\n",
              "3      23.000000\n",
              "4      20.000000\n",
              "...          ...\n",
              "1687  244.820007\n",
              "1688  246.110001\n",
              "1689  257.000000\n",
              "1690  262.399994\n",
              "1691  264.000000\n",
              "\n",
              "[1692 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deSSXB4xXymi",
        "colab_type": "code",
        "outputId": "65d52f2f-357d-4fe3-efc4-cb014b3683cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df['d1']=0.0\n",
        "df['d2']=0.0\n",
        "df['d3']=0.0\n",
        "df['d4']=0.0\n",
        "df['target']=0.0\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>d1</th>\n",
              "      <th>d2</th>\n",
              "      <th>d3</th>\n",
              "      <th>d4</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.790001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Open   d1   d2   d3   d4  target\n",
              "0  19.000000  0.0  0.0  0.0  0.0     0.0\n",
              "1  25.790001  0.0  0.0  0.0  0.0     0.0\n",
              "2  25.000000  0.0  0.0  0.0  0.0     0.0\n",
              "3  23.000000  0.0  0.0  0.0  0.0     0.0\n",
              "4  20.000000  0.0  0.0  0.0  0.0     0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYvadJQK7TlP",
        "colab_type": "code",
        "outputId": "10df1e3a-504f-4d9c-ec7d-2df13442a6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "for i in range(1000):\n",
        "  df.iloc[i,1]=df.iloc[i+1,0]\n",
        "  df.iloc[i,2]=df.iloc[i+2,0]\n",
        "  df.iloc[i,3]=df.iloc[i+3,0]\n",
        "  df.iloc[i,4]=df.iloc[i+4,0]\n",
        "  df.iloc[i,5]=df.iloc[i+5,0]\n",
        "ndf=df[:1000].copy()\n",
        "y=np.array(ndf['target'])\n",
        "ndf=ndf.drop(columns='target',axis=1)\n",
        "X=np.array(ndf)\n",
        "print(X.shape)\n",
        "print(X[:3])\n",
        "X=X[:,:,np.newaxis]\n",
        "print(X.shape)\n",
        "X[:3]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 5)\n",
            "[[19.       25.790001 25.       23.       20.      ]\n",
            " [25.790001 25.       23.       20.       16.4     ]\n",
            " [25.       23.       20.       16.4      16.139999]]\n",
            "(1000, 5, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[19.      ],\n",
              "        [25.790001],\n",
              "        [25.      ],\n",
              "        [23.      ],\n",
              "        [20.      ]],\n",
              "\n",
              "       [[25.790001],\n",
              "        [25.      ],\n",
              "        [23.      ],\n",
              "        [20.      ],\n",
              "        [16.4     ]],\n",
              "\n",
              "       [[25.      ],\n",
              "        [23.      ],\n",
              "        [20.      ],\n",
              "        [16.4     ],\n",
              "        [16.139999]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk2nFGgDePsc",
        "colab_type": "code",
        "outputId": "e90f56b3-a42e-4d20-8f1b-50a79e0b0128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(10, activation='relu', input_shape=(5, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 1s 809us/step - loss: 7531.9666\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 0s 144us/step - loss: 4667.0619\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 0s 133us/step - loss: 3009.0811\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 0s 141us/step - loss: 609.7099\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 0s 141us/step - loss: 66.1019\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 55.5832\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 52.0169\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - 0s 143us/step - loss: 50.6539\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - 0s 140us/step - loss: 49.1756\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - 0s 154us/step - loss: 47.2450\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - 0s 154us/step - loss: 43.5263\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - 0s 137us/step - loss: 34.6523\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 32.3176\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - 0s 143us/step - loss: 28.1389\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - 0s 137us/step - loss: 25.6953\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - 0s 143us/step - loss: 25.2475\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 19.6862\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 19.0628\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - 0s 158us/step - loss: 19.2408\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - 0s 154us/step - loss: 17.2791\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - 0s 144us/step - loss: 16.7956\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - 0s 141us/step - loss: 16.6625\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 18.7090\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - 0s 140us/step - loss: 17.6022\n",
            "Epoch 25/200\n",
            "1000/1000 [==============================] - 0s 144us/step - loss: 16.5114\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 17.3439\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 17.6639\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 16.3526\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 17.4218\n",
            "Epoch 30/200\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 16.2527\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 16.5712\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 16.3228\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 16.2213\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 17.9334\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 16.5187\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 16.3108\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - 0s 155us/step - loss: 16.2740\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.6738\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.7874\n",
            "Epoch 40/200\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 16.5097\n",
            "Epoch 41/200\n",
            "1000/1000 [==============================] - 0s 164us/step - loss: 15.3516\n",
            "Epoch 42/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 17.3130\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 16.0475\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - 0s 158us/step - loss: 15.7202\n",
            "Epoch 45/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.8846\n",
            "Epoch 46/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.3764\n",
            "Epoch 47/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 15.5043\n",
            "Epoch 48/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 15.0809\n",
            "Epoch 49/200\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 15.1172\n",
            "Epoch 50/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 15.2180\n",
            "Epoch 51/200\n",
            "1000/1000 [==============================] - 0s 160us/step - loss: 15.9672\n",
            "Epoch 52/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 15.5497\n",
            "Epoch 53/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.3390\n",
            "Epoch 54/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 15.8366\n",
            "Epoch 55/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.3867\n",
            "Epoch 56/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.4061\n",
            "Epoch 57/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.5715\n",
            "Epoch 58/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 14.9888\n",
            "Epoch 59/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 14.8525\n",
            "Epoch 60/200\n",
            "1000/1000 [==============================] - 0s 159us/step - loss: 15.1168\n",
            "Epoch 61/200\n",
            "1000/1000 [==============================] - 0s 164us/step - loss: 17.7716\n",
            "Epoch 62/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 16.3803\n",
            "Epoch 63/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.6448\n",
            "Epoch 64/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 16.5818\n",
            "Epoch 65/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 15.2290\n",
            "Epoch 66/200\n",
            "1000/1000 [==============================] - 0s 161us/step - loss: 14.9074\n",
            "Epoch 67/200\n",
            "1000/1000 [==============================] - 0s 154us/step - loss: 15.1709\n",
            "Epoch 68/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.2677\n",
            "Epoch 69/200\n",
            "1000/1000 [==============================] - 0s 160us/step - loss: 16.0577\n",
            "Epoch 70/200\n",
            "1000/1000 [==============================] - 0s 165us/step - loss: 14.9196\n",
            "Epoch 71/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 14.9779\n",
            "Epoch 72/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.7595\n",
            "Epoch 73/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.7512\n",
            "Epoch 74/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.6114\n",
            "Epoch 75/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.4640\n",
            "Epoch 76/200\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 15.5147\n",
            "Epoch 77/200\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 16.5311\n",
            "Epoch 78/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 14.9471\n",
            "Epoch 79/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.6553\n",
            "Epoch 80/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 14.7221\n",
            "Epoch 81/200\n",
            "1000/1000 [==============================] - 0s 155us/step - loss: 15.7043\n",
            "Epoch 82/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.6342\n",
            "Epoch 83/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.0793\n",
            "Epoch 84/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 16.1174\n",
            "Epoch 85/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 14.9866\n",
            "Epoch 86/200\n",
            "1000/1000 [==============================] - 0s 161us/step - loss: 15.4656\n",
            "Epoch 87/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.4122\n",
            "Epoch 88/200\n",
            "1000/1000 [==============================] - 0s 161us/step - loss: 15.1446\n",
            "Epoch 89/200\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 14.8671\n",
            "Epoch 90/200\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 15.0068\n",
            "Epoch 91/200\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 15.1089\n",
            "Epoch 92/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.0941\n",
            "Epoch 93/200\n",
            "1000/1000 [==============================] - 0s 140us/step - loss: 16.5357\n",
            "Epoch 94/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 15.4124\n",
            "Epoch 95/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.0552\n",
            "Epoch 96/200\n",
            "1000/1000 [==============================] - 0s 161us/step - loss: 14.8717\n",
            "Epoch 97/200\n",
            "1000/1000 [==============================] - 0s 155us/step - loss: 15.6441\n",
            "Epoch 98/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.3105\n",
            "Epoch 99/200\n",
            "1000/1000 [==============================] - 0s 159us/step - loss: 14.7520\n",
            "Epoch 100/200\n",
            "1000/1000 [==============================] - 0s 160us/step - loss: 15.5730\n",
            "Epoch 101/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 15.6868\n",
            "Epoch 102/200\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 15.4288\n",
            "Epoch 103/200\n",
            "1000/1000 [==============================] - 0s 161us/step - loss: 14.5342\n",
            "Epoch 104/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.3190\n",
            "Epoch 105/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.1393\n",
            "Epoch 106/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 14.9183\n",
            "Epoch 107/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 16.5555\n",
            "Epoch 108/200\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 15.0194\n",
            "Epoch 109/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 15.9143\n",
            "Epoch 110/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.2506\n",
            "Epoch 111/200\n",
            "1000/1000 [==============================] - 0s 163us/step - loss: 15.3071\n",
            "Epoch 112/200\n",
            "1000/1000 [==============================] - 0s 155us/step - loss: 15.0544\n",
            "Epoch 113/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 14.9160\n",
            "Epoch 114/200\n",
            "1000/1000 [==============================] - 0s 140us/step - loss: 14.5650\n",
            "Epoch 115/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.1683\n",
            "Epoch 116/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.0058\n",
            "Epoch 117/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.6083\n",
            "Epoch 118/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.7390\n",
            "Epoch 119/200\n",
            "1000/1000 [==============================] - 0s 159us/step - loss: 15.2567\n",
            "Epoch 120/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 15.6764\n",
            "Epoch 121/200\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 15.2088\n",
            "Epoch 122/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 16.9649\n",
            "Epoch 123/200\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 15.7209\n",
            "Epoch 124/200\n",
            "1000/1000 [==============================] - 0s 155us/step - loss: 14.8703\n",
            "Epoch 125/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.7513\n",
            "Epoch 126/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 14.9120\n",
            "Epoch 127/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 15.6173\n",
            "Epoch 128/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 14.8679\n",
            "Epoch 129/200\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 15.7430\n",
            "Epoch 130/200\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 14.7966\n",
            "Epoch 131/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 15.6218\n",
            "Epoch 132/200\n",
            "1000/1000 [==============================] - 0s 144us/step - loss: 15.9852\n",
            "Epoch 133/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.7073\n",
            "Epoch 134/200\n",
            "1000/1000 [==============================] - 0s 154us/step - loss: 15.2874\n",
            "Epoch 135/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 15.5394\n",
            "Epoch 136/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.5255\n",
            "Epoch 137/200\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 16.6027\n",
            "Epoch 138/200\n",
            "1000/1000 [==============================] - 0s 139us/step - loss: 15.4334\n",
            "Epoch 139/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.3692\n",
            "Epoch 140/200\n",
            "1000/1000 [==============================] - 0s 167us/step - loss: 15.0625\n",
            "Epoch 141/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 14.5906\n",
            "Epoch 142/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 14.8295\n",
            "Epoch 143/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 15.2995\n",
            "Epoch 144/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 14.9415\n",
            "Epoch 145/200\n",
            "1000/1000 [==============================] - 0s 139us/step - loss: 15.1246\n",
            "Epoch 146/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 15.3886\n",
            "Epoch 147/200\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 15.0214\n",
            "Epoch 148/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.0160\n",
            "Epoch 149/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 16.1817\n",
            "Epoch 150/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 16.2828\n",
            "Epoch 151/200\n",
            "1000/1000 [==============================] - 0s 155us/step - loss: 14.2861\n",
            "Epoch 152/200\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 15.3280\n",
            "Epoch 153/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 14.9937\n",
            "Epoch 154/200\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 15.4479\n",
            "Epoch 155/200\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 15.7373\n",
            "Epoch 156/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 14.6660\n",
            "Epoch 157/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 14.7969\n",
            "Epoch 158/200\n",
            "1000/1000 [==============================] - 0s 163us/step - loss: 15.6302\n",
            "Epoch 159/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 14.7046\n",
            "Epoch 160/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 15.0200\n",
            "Epoch 161/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.4657\n",
            "Epoch 162/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 14.7315\n",
            "Epoch 163/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 14.7217\n",
            "Epoch 164/200\n",
            "1000/1000 [==============================] - 0s 163us/step - loss: 15.2468\n",
            "Epoch 165/200\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 15.0769\n",
            "Epoch 166/200\n",
            "1000/1000 [==============================] - 0s 144us/step - loss: 15.3295\n",
            "Epoch 167/200\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 15.0193\n",
            "Epoch 168/200\n",
            "1000/1000 [==============================] - 0s 142us/step - loss: 14.9517\n",
            "Epoch 169/200\n",
            "1000/1000 [==============================] - 0s 145us/step - loss: 14.6306\n",
            "Epoch 170/200\n",
            "1000/1000 [==============================] - 0s 143us/step - loss: 15.9406\n",
            "Epoch 171/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 16.0432\n",
            "Epoch 172/200\n",
            "1000/1000 [==============================] - 0s 139us/step - loss: 15.1033\n",
            "Epoch 173/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.3726\n",
            "Epoch 174/200\n",
            "1000/1000 [==============================] - 0s 141us/step - loss: 16.6821\n",
            "Epoch 175/200\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 15.7269\n",
            "Epoch 176/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.8801\n",
            "Epoch 177/200\n",
            "1000/1000 [==============================] - 0s 162us/step - loss: 14.7248\n",
            "Epoch 178/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 15.2011\n",
            "Epoch 179/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 15.3875\n",
            "Epoch 180/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 16.2427\n",
            "Epoch 181/200\n",
            "1000/1000 [==============================] - 0s 158us/step - loss: 16.3055\n",
            "Epoch 182/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 15.3139\n",
            "Epoch 183/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 14.7939\n",
            "Epoch 184/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 14.9445\n",
            "Epoch 185/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 14.8640\n",
            "Epoch 186/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 14.7786\n",
            "Epoch 187/200\n",
            "1000/1000 [==============================] - 0s 150us/step - loss: 15.6030\n",
            "Epoch 188/200\n",
            "1000/1000 [==============================] - 0s 144us/step - loss: 16.1716\n",
            "Epoch 189/200\n",
            "1000/1000 [==============================] - 0s 146us/step - loss: 15.2151\n",
            "Epoch 190/200\n",
            "1000/1000 [==============================] - 0s 143us/step - loss: 15.4834\n",
            "Epoch 191/200\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 16.9506\n",
            "Epoch 192/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 17.4463\n",
            "Epoch 193/200\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 15.3311\n",
            "Epoch 194/200\n",
            "1000/1000 [==============================] - 0s 148us/step - loss: 16.0030\n",
            "Epoch 195/200\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 15.5161\n",
            "Epoch 196/200\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 15.3216\n",
            "Epoch 197/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.8704\n",
            "Epoch 198/200\n",
            "1000/1000 [==============================] - 0s 159us/step - loss: 17.0298\n",
            "Epoch 199/200\n",
            "1000/1000 [==============================] - 0s 166us/step - loss: 16.0421\n",
            "Epoch 200/200\n",
            "1000/1000 [==============================] - 0s 151us/step - loss: 15.4566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd56d609b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhc9VNenlJ1r",
        "colab_type": "code",
        "outputId": "67effe54-33fd-430e-8b47-8342aa1eb894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "ye = model.predict(X)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ye, color='blue')\n",
        "plt.plot(y, color='red')\n",
        "plt.show()\n",
        "\n",
        "y[100], ye[100] # estimate nth day."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/zP0kJrX4rDcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35.599998, array([34.053783], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUb8Gbfol-kI",
        "colab_type": "code",
        "outputId": "21a4862e-3920-4daa-b827-444973540429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 10)                480       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 491\n",
            "Trainable params: 491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}