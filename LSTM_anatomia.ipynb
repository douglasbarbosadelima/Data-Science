{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_anatomia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/douglasbarbosadelima/Data-Science/blob/master/LSTM_anatomia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePVO9pOJ6jgh",
        "colab_type": "text"
      },
      "source": [
        "# LSTM_Anatomia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkP4tMDxGVnf",
        "colab_type": "code",
        "outputId": "135f4d3e-7123-4c1c-e415-b4890b7b0dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "!pip install tensorflow===2.1.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow===2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (3.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.27.2)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (0.1.8)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.17.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.0.8)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.1.0) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow===2.1.0) (45.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow===2.1.0) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (3.2.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow===2.1.0) (3.1.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHL2w9KxTFRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwilz_qnTIdP",
        "colab_type": "code",
        "outputId": "78bb3668-3800-4787-999f-5701956ac585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Montagem do Datraset de Treinamento\n",
        "random.seed(42)\n",
        "y=[]\n",
        "seq=[]\n",
        "for i in range(100):\n",
        "  ini=random.randint(1,15)\n",
        "  seq1=[]\n",
        "  for j in range(3):\n",
        "    seq1.append([ini+j])\n",
        "  seq.append(seq1)\n",
        "  y.append([ini+3])\n",
        "\n",
        "\n",
        "X=np.array(seq)\n",
        "y=np.array(y)\n",
        "X[:3],y[:3]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[11],\n",
              "         [12],\n",
              "         [13]],\n",
              " \n",
              "        [[ 2],\n",
              "         [ 3],\n",
              "         [ 4]],\n",
              " \n",
              "        [[ 1],\n",
              "         [ 2],\n",
              "         [ 3]]]), array([[14],\n",
              "        [ 5],\n",
              "        [ 4]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk2nFGgDePsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8a072dd1-089e-436f-b59b-2816f8acfd13"
      },
      "source": [
        "#Criação do Modelo\n",
        "model = tf.keras.Sequential()\n",
        "#inserir uma camada LSTM com 1 célula\n",
        "model.add(tf.keras.layers.LSTM(1, activation=lambda x: x, input_shape=(None, 1)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OcPohNEMd65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "704d3eed-08a3-4bd0-d2e8-35b407cd40a4"
      },
      "source": [
        "hist=model.fit(X, y, epochs=500,validation_split=0.3, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 70 samples, validate on 30 samples\n",
            "Epoch 1/500\n",
            "70/70 [==============================] - 1s 15ms/sample - loss: 119.9444 - val_loss: 139.3865\n",
            "Epoch 2/500\n",
            "70/70 [==============================] - 0s 320us/sample - loss: 119.9333 - val_loss: 139.3778\n",
            "Epoch 3/500\n",
            "70/70 [==============================] - 0s 278us/sample - loss: 119.9219 - val_loss: 139.3693\n",
            "Epoch 4/500\n",
            "70/70 [==============================] - 0s 274us/sample - loss: 119.9123 - val_loss: 139.3609\n",
            "Epoch 5/500\n",
            "70/70 [==============================] - 0s 268us/sample - loss: 119.9009 - val_loss: 139.3526\n",
            "Epoch 6/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 119.8906 - val_loss: 139.3443\n",
            "Epoch 7/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 119.8799 - val_loss: 139.3361\n",
            "Epoch 8/500\n",
            "70/70 [==============================] - 0s 279us/sample - loss: 119.8700 - val_loss: 139.3280\n",
            "Epoch 9/500\n",
            "70/70 [==============================] - 0s 263us/sample - loss: 119.8598 - val_loss: 139.3201\n",
            "Epoch 10/500\n",
            "70/70 [==============================] - 0s 278us/sample - loss: 119.8499 - val_loss: 139.3126\n",
            "Epoch 11/500\n",
            "70/70 [==============================] - 0s 298us/sample - loss: 119.8406 - val_loss: 139.3052\n",
            "Epoch 12/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 119.8316 - val_loss: 139.2982\n",
            "Epoch 13/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 119.8224 - val_loss: 139.2917\n",
            "Epoch 14/500\n",
            "70/70 [==============================] - 0s 301us/sample - loss: 119.8145 - val_loss: 139.2855\n",
            "Epoch 15/500\n",
            "70/70 [==============================] - 0s 320us/sample - loss: 119.8064 - val_loss: 139.2795\n",
            "Epoch 16/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 119.7992 - val_loss: 139.2735\n",
            "Epoch 17/500\n",
            "70/70 [==============================] - 0s 425us/sample - loss: 119.7910 - val_loss: 139.2677\n",
            "Epoch 18/500\n",
            "70/70 [==============================] - 0s 362us/sample - loss: 119.7840 - val_loss: 139.2618\n",
            "Epoch 19/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 119.7764 - val_loss: 139.2563\n",
            "Epoch 20/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 119.7693 - val_loss: 139.2509\n",
            "Epoch 21/500\n",
            "70/70 [==============================] - 0s 318us/sample - loss: 119.7623 - val_loss: 139.2456\n",
            "Epoch 22/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 119.7558 - val_loss: 139.2404\n",
            "Epoch 23/500\n",
            "70/70 [==============================] - 0s 280us/sample - loss: 119.7491 - val_loss: 139.2354\n",
            "Epoch 24/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 119.7422 - val_loss: 139.2304\n",
            "Epoch 25/500\n",
            "70/70 [==============================] - 0s 313us/sample - loss: 119.7362 - val_loss: 139.2255\n",
            "Epoch 26/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 119.7296 - val_loss: 139.2209\n",
            "Epoch 27/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 119.7239 - val_loss: 139.2165\n",
            "Epoch 28/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 119.7180 - val_loss: 139.2120\n",
            "Epoch 29/500\n",
            "70/70 [==============================] - 0s 298us/sample - loss: 119.7122 - val_loss: 139.2076\n",
            "Epoch 30/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 119.7064 - val_loss: 139.2033\n",
            "Epoch 31/500\n",
            "70/70 [==============================] - 0s 337us/sample - loss: 119.7006 - val_loss: 139.1991\n",
            "Epoch 32/500\n",
            "70/70 [==============================] - 0s 320us/sample - loss: 119.6952 - val_loss: 139.1948\n",
            "Epoch 33/500\n",
            "70/70 [==============================] - 0s 312us/sample - loss: 119.6899 - val_loss: 139.1905\n",
            "Epoch 34/500\n",
            "70/70 [==============================] - 0s 370us/sample - loss: 119.6841 - val_loss: 139.1866\n",
            "Epoch 35/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 119.6790 - val_loss: 139.1827\n",
            "Epoch 36/500\n",
            "70/70 [==============================] - 0s 289us/sample - loss: 119.6742 - val_loss: 139.1790\n",
            "Epoch 37/500\n",
            "70/70 [==============================] - 0s 279us/sample - loss: 119.6692 - val_loss: 139.1755\n",
            "Epoch 38/500\n",
            "70/70 [==============================] - 0s 331us/sample - loss: 119.6646 - val_loss: 139.1720\n",
            "Epoch 39/500\n",
            "70/70 [==============================] - 0s 276us/sample - loss: 119.6599 - val_loss: 139.1686\n",
            "Epoch 40/500\n",
            "70/70 [==============================] - 0s 276us/sample - loss: 119.6554 - val_loss: 139.1652\n",
            "Epoch 41/500\n",
            "70/70 [==============================] - 0s 296us/sample - loss: 119.6507 - val_loss: 139.1620\n",
            "Epoch 42/500\n",
            "70/70 [==============================] - 0s 264us/sample - loss: 119.6467 - val_loss: 139.1587\n",
            "Epoch 43/500\n",
            "70/70 [==============================] - 0s 281us/sample - loss: 119.6423 - val_loss: 139.1554\n",
            "Epoch 44/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 119.6379 - val_loss: 139.1521\n",
            "Epoch 45/500\n",
            "70/70 [==============================] - 0s 337us/sample - loss: 119.6337 - val_loss: 139.1491\n",
            "Epoch 46/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 119.6296 - val_loss: 139.1462\n",
            "Epoch 47/500\n",
            "70/70 [==============================] - 0s 295us/sample - loss: 119.6258 - val_loss: 139.1434\n",
            "Epoch 48/500\n",
            "70/70 [==============================] - 0s 288us/sample - loss: 119.6218 - val_loss: 139.1407\n",
            "Epoch 49/500\n",
            "70/70 [==============================] - 0s 295us/sample - loss: 119.6183 - val_loss: 139.1380\n",
            "Epoch 50/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 119.6146 - val_loss: 139.1353\n",
            "Epoch 51/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 119.6108 - val_loss: 139.1326\n",
            "Epoch 52/500\n",
            "70/70 [==============================] - 0s 283us/sample - loss: 119.6073 - val_loss: 139.1298\n",
            "Epoch 53/500\n",
            "70/70 [==============================] - 0s 319us/sample - loss: 119.6038 - val_loss: 139.1272\n",
            "Epoch 54/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 119.6001 - val_loss: 139.1246\n",
            "Epoch 55/500\n",
            "70/70 [==============================] - 0s 301us/sample - loss: 119.5967 - val_loss: 139.1221\n",
            "Epoch 56/500\n",
            "70/70 [==============================] - 0s 302us/sample - loss: 119.5934 - val_loss: 139.1197\n",
            "Epoch 57/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 119.5901 - val_loss: 139.1173\n",
            "Epoch 58/500\n",
            "70/70 [==============================] - 0s 324us/sample - loss: 119.5869 - val_loss: 139.1149\n",
            "Epoch 59/500\n",
            "70/70 [==============================] - 0s 298us/sample - loss: 119.5835 - val_loss: 139.1126\n",
            "Epoch 60/500\n",
            "70/70 [==============================] - 0s 318us/sample - loss: 119.5802 - val_loss: 139.1102\n",
            "Epoch 61/500\n",
            "70/70 [==============================] - 0s 326us/sample - loss: 119.5771 - val_loss: 139.1078\n",
            "Epoch 62/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 119.5741 - val_loss: 139.1054\n",
            "Epoch 63/500\n",
            "70/70 [==============================] - 0s 330us/sample - loss: 119.5706 - val_loss: 139.1030\n",
            "Epoch 64/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 119.5673 - val_loss: 139.1007\n",
            "Epoch 65/500\n",
            "70/70 [==============================] - 0s 317us/sample - loss: 119.5642 - val_loss: 139.0984\n",
            "Epoch 66/500\n",
            "70/70 [==============================] - 0s 355us/sample - loss: 119.5611 - val_loss: 139.0961\n",
            "Epoch 67/500\n",
            "70/70 [==============================] - 0s 288us/sample - loss: 119.5578 - val_loss: 139.0938\n",
            "Epoch 68/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 119.5549 - val_loss: 139.0916\n",
            "Epoch 69/500\n",
            "70/70 [==============================] - 0s 285us/sample - loss: 119.5520 - val_loss: 139.0895\n",
            "Epoch 70/500\n",
            "70/70 [==============================] - 0s 287us/sample - loss: 119.5489 - val_loss: 139.0874\n",
            "Epoch 71/500\n",
            "70/70 [==============================] - 0s 392us/sample - loss: 119.5461 - val_loss: 139.0854\n",
            "Epoch 72/500\n",
            "70/70 [==============================] - 0s 350us/sample - loss: 119.5431 - val_loss: 139.0832\n",
            "Epoch 73/500\n",
            "70/70 [==============================] - 0s 307us/sample - loss: 119.5402 - val_loss: 139.0811\n",
            "Epoch 74/500\n",
            "70/70 [==============================] - 0s 360us/sample - loss: 119.5372 - val_loss: 139.0790\n",
            "Epoch 75/500\n",
            "70/70 [==============================] - 0s 366us/sample - loss: 119.5343 - val_loss: 139.0770\n",
            "Epoch 76/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 119.5315 - val_loss: 139.0749\n",
            "Epoch 77/500\n",
            "70/70 [==============================] - 0s 278us/sample - loss: 119.5286 - val_loss: 139.0728\n",
            "Epoch 78/500\n",
            "70/70 [==============================] - 0s 323us/sample - loss: 119.5256 - val_loss: 139.0709\n",
            "Epoch 79/500\n",
            "70/70 [==============================] - 0s 323us/sample - loss: 119.5230 - val_loss: 139.0688\n",
            "Epoch 80/500\n",
            "70/70 [==============================] - 0s 297us/sample - loss: 119.5200 - val_loss: 139.0667\n",
            "Epoch 81/500\n",
            "70/70 [==============================] - 0s 396us/sample - loss: 119.5172 - val_loss: 139.0646\n",
            "Epoch 82/500\n",
            "70/70 [==============================] - 0s 301us/sample - loss: 119.5143 - val_loss: 139.0626\n",
            "Epoch 83/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 119.5117 - val_loss: 139.0606\n",
            "Epoch 84/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 119.5087 - val_loss: 139.0586\n",
            "Epoch 85/500\n",
            "70/70 [==============================] - 0s 372us/sample - loss: 119.5056 - val_loss: 139.0565\n",
            "Epoch 86/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 119.5030 - val_loss: 139.0544\n",
            "Epoch 87/500\n",
            "70/70 [==============================] - 0s 321us/sample - loss: 119.5000 - val_loss: 139.0524\n",
            "Epoch 88/500\n",
            "70/70 [==============================] - 0s 294us/sample - loss: 119.4969 - val_loss: 139.0503\n",
            "Epoch 89/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 119.4941 - val_loss: 139.0480\n",
            "Epoch 90/500\n",
            "70/70 [==============================] - 0s 329us/sample - loss: 119.4911 - val_loss: 139.0458\n",
            "Epoch 91/500\n",
            "70/70 [==============================] - 0s 388us/sample - loss: 119.4879 - val_loss: 139.0435\n",
            "Epoch 92/500\n",
            "70/70 [==============================] - 0s 301us/sample - loss: 119.4847 - val_loss: 139.0414\n",
            "Epoch 93/500\n",
            "70/70 [==============================] - 0s 344us/sample - loss: 119.4816 - val_loss: 139.0392\n",
            "Epoch 94/500\n",
            "70/70 [==============================] - 0s 347us/sample - loss: 119.4786 - val_loss: 139.0369\n",
            "Epoch 95/500\n",
            "70/70 [==============================] - 0s 314us/sample - loss: 119.4753 - val_loss: 139.0346\n",
            "Epoch 96/500\n",
            "70/70 [==============================] - 0s 338us/sample - loss: 119.4722 - val_loss: 139.0323\n",
            "Epoch 97/500\n",
            "70/70 [==============================] - 0s 343us/sample - loss: 119.4688 - val_loss: 139.0301\n",
            "Epoch 98/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 119.4656 - val_loss: 139.0278\n",
            "Epoch 99/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 119.4622 - val_loss: 139.0254\n",
            "Epoch 100/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 119.4586 - val_loss: 139.0228\n",
            "Epoch 101/500\n",
            "70/70 [==============================] - 0s 325us/sample - loss: 119.4554 - val_loss: 139.0202\n",
            "Epoch 102/500\n",
            "70/70 [==============================] - 0s 395us/sample - loss: 119.4515 - val_loss: 139.0176\n",
            "Epoch 103/500\n",
            "70/70 [==============================] - 0s 367us/sample - loss: 119.4478 - val_loss: 139.0149\n",
            "Epoch 104/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 119.4441 - val_loss: 139.0120\n",
            "Epoch 105/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 119.4400 - val_loss: 139.0093\n",
            "Epoch 106/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 119.4359 - val_loss: 139.0064\n",
            "Epoch 107/500\n",
            "70/70 [==============================] - 0s 352us/sample - loss: 119.4321 - val_loss: 139.0034\n",
            "Epoch 108/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 119.4281 - val_loss: 139.0005\n",
            "Epoch 109/500\n",
            "70/70 [==============================] - 0s 293us/sample - loss: 119.4238 - val_loss: 138.9978\n",
            "Epoch 110/500\n",
            "70/70 [==============================] - 0s 362us/sample - loss: 119.4200 - val_loss: 138.9949\n",
            "Epoch 111/500\n",
            "70/70 [==============================] - 0s 292us/sample - loss: 119.4159 - val_loss: 138.9919\n",
            "Epoch 112/500\n",
            "70/70 [==============================] - 0s 357us/sample - loss: 119.4117 - val_loss: 138.9887\n",
            "Epoch 113/500\n",
            "70/70 [==============================] - 0s 322us/sample - loss: 119.4071 - val_loss: 138.9854\n",
            "Epoch 114/500\n",
            "70/70 [==============================] - 0s 303us/sample - loss: 119.4026 - val_loss: 138.9820\n",
            "Epoch 115/500\n",
            "70/70 [==============================] - 0s 381us/sample - loss: 119.3975 - val_loss: 138.9786\n",
            "Epoch 116/500\n",
            "70/70 [==============================] - 0s 336us/sample - loss: 119.3930 - val_loss: 138.9751\n",
            "Epoch 117/500\n",
            "70/70 [==============================] - 0s 292us/sample - loss: 119.3878 - val_loss: 138.9716\n",
            "Epoch 118/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 119.3832 - val_loss: 138.9679\n",
            "Epoch 119/500\n",
            "70/70 [==============================] - 0s 335us/sample - loss: 119.3782 - val_loss: 138.9643\n",
            "Epoch 120/500\n",
            "70/70 [==============================] - 0s 373us/sample - loss: 119.3735 - val_loss: 138.9606\n",
            "Epoch 121/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 119.3676 - val_loss: 138.9568\n",
            "Epoch 122/500\n",
            "70/70 [==============================] - 0s 418us/sample - loss: 119.3624 - val_loss: 138.9525\n",
            "Epoch 123/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 119.3566 - val_loss: 138.9482\n",
            "Epoch 124/500\n",
            "70/70 [==============================] - 0s 317us/sample - loss: 119.3507 - val_loss: 138.9437\n",
            "Epoch 125/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 119.3449 - val_loss: 138.9393\n",
            "Epoch 126/500\n",
            "70/70 [==============================] - 0s 326us/sample - loss: 119.3381 - val_loss: 138.9349\n",
            "Epoch 127/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 119.3324 - val_loss: 138.9301\n",
            "Epoch 128/500\n",
            "70/70 [==============================] - 0s 307us/sample - loss: 119.3256 - val_loss: 138.9252\n",
            "Epoch 129/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 119.3187 - val_loss: 138.9202\n",
            "Epoch 130/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 119.3118 - val_loss: 138.9146\n",
            "Epoch 131/500\n",
            "70/70 [==============================] - 0s 364us/sample - loss: 119.3046 - val_loss: 138.9088\n",
            "Epoch 132/500\n",
            "70/70 [==============================] - 0s 388us/sample - loss: 119.2965 - val_loss: 138.9030\n",
            "Epoch 133/500\n",
            "70/70 [==============================] - 0s 379us/sample - loss: 119.2890 - val_loss: 138.8970\n",
            "Epoch 134/500\n",
            "70/70 [==============================] - 0s 344us/sample - loss: 119.2804 - val_loss: 138.8907\n",
            "Epoch 135/500\n",
            "70/70 [==============================] - 0s 333us/sample - loss: 119.2723 - val_loss: 138.8842\n",
            "Epoch 136/500\n",
            "70/70 [==============================] - 0s 305us/sample - loss: 119.2630 - val_loss: 138.8773\n",
            "Epoch 137/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 119.2543 - val_loss: 138.8697\n",
            "Epoch 138/500\n",
            "70/70 [==============================] - 0s 338us/sample - loss: 119.2444 - val_loss: 138.8618\n",
            "Epoch 139/500\n",
            "70/70 [==============================] - 0s 337us/sample - loss: 119.2339 - val_loss: 138.8534\n",
            "Epoch 140/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 119.2219 - val_loss: 138.8447\n",
            "Epoch 141/500\n",
            "70/70 [==============================] - 0s 312us/sample - loss: 119.2110 - val_loss: 138.8351\n",
            "Epoch 142/500\n",
            "70/70 [==============================] - 0s 327us/sample - loss: 119.1977 - val_loss: 138.8251\n",
            "Epoch 143/500\n",
            "70/70 [==============================] - 0s 434us/sample - loss: 119.1848 - val_loss: 138.8147\n",
            "Epoch 144/500\n",
            "70/70 [==============================] - 0s 312us/sample - loss: 119.1714 - val_loss: 138.8035\n",
            "Epoch 145/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 119.1578 - val_loss: 138.7919\n",
            "Epoch 146/500\n",
            "70/70 [==============================] - 0s 370us/sample - loss: 119.1420 - val_loss: 138.7807\n",
            "Epoch 147/500\n",
            "70/70 [==============================] - 0s 307us/sample - loss: 119.1268 - val_loss: 138.7691\n",
            "Epoch 148/500\n",
            "70/70 [==============================] - 0s 294us/sample - loss: 119.1128 - val_loss: 138.7564\n",
            "Epoch 149/500\n",
            "70/70 [==============================] - 0s 343us/sample - loss: 119.0967 - val_loss: 138.7437\n",
            "Epoch 150/500\n",
            "70/70 [==============================] - 0s 333us/sample - loss: 119.0802 - val_loss: 138.7303\n",
            "Epoch 151/500\n",
            "70/70 [==============================] - 0s 446us/sample - loss: 119.0631 - val_loss: 138.7159\n",
            "Epoch 152/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 119.0453 - val_loss: 138.7005\n",
            "Epoch 153/500\n",
            "70/70 [==============================] - 0s 339us/sample - loss: 119.0256 - val_loss: 138.6846\n",
            "Epoch 154/500\n",
            "70/70 [==============================] - 0s 379us/sample - loss: 119.0047 - val_loss: 138.6676\n",
            "Epoch 155/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 118.9841 - val_loss: 138.6484\n",
            "Epoch 156/500\n",
            "70/70 [==============================] - 0s 288us/sample - loss: 118.9597 - val_loss: 138.6281\n",
            "Epoch 157/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 118.9340 - val_loss: 138.6065\n",
            "Epoch 158/500\n",
            "70/70 [==============================] - 0s 265us/sample - loss: 118.9077 - val_loss: 138.5831\n",
            "Epoch 159/500\n",
            "70/70 [==============================] - 0s 368us/sample - loss: 118.8794 - val_loss: 138.5581\n",
            "Epoch 160/500\n",
            "70/70 [==============================] - 0s 321us/sample - loss: 118.8480 - val_loss: 138.5315\n",
            "Epoch 161/500\n",
            "70/70 [==============================] - 0s 283us/sample - loss: 118.8164 - val_loss: 138.5032\n",
            "Epoch 162/500\n",
            "70/70 [==============================] - 0s 280us/sample - loss: 118.7829 - val_loss: 138.4748\n",
            "Epoch 163/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 118.7482 - val_loss: 138.4457\n",
            "Epoch 164/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 118.7138 - val_loss: 138.4144\n",
            "Epoch 165/500\n",
            "70/70 [==============================] - 0s 323us/sample - loss: 118.6759 - val_loss: 138.3806\n",
            "Epoch 166/500\n",
            "70/70 [==============================] - 0s 347us/sample - loss: 118.6348 - val_loss: 138.3440\n",
            "Epoch 167/500\n",
            "70/70 [==============================] - 0s 327us/sample - loss: 118.5909 - val_loss: 138.3038\n",
            "Epoch 168/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 118.5435 - val_loss: 138.2599\n",
            "Epoch 169/500\n",
            "70/70 [==============================] - 0s 329us/sample - loss: 118.4941 - val_loss: 138.2119\n",
            "Epoch 170/500\n",
            "70/70 [==============================] - 0s 286us/sample - loss: 118.4380 - val_loss: 138.1605\n",
            "Epoch 171/500\n",
            "70/70 [==============================] - 0s 256us/sample - loss: 118.3767 - val_loss: 138.1055\n",
            "Epoch 172/500\n",
            "70/70 [==============================] - 0s 307us/sample - loss: 118.3136 - val_loss: 138.0441\n",
            "Epoch 173/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 118.2417 - val_loss: 137.9763\n",
            "Epoch 174/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 118.1663 - val_loss: 137.9034\n",
            "Epoch 175/500\n",
            "70/70 [==============================] - 0s 490us/sample - loss: 118.0814 - val_loss: 137.8243\n",
            "Epoch 176/500\n",
            "70/70 [==============================] - 0s 386us/sample - loss: 117.9926 - val_loss: 137.7363\n",
            "Epoch 177/500\n",
            "70/70 [==============================] - 0s 322us/sample - loss: 117.8942 - val_loss: 137.6413\n",
            "Epoch 178/500\n",
            "70/70 [==============================] - 0s 368us/sample - loss: 117.7841 - val_loss: 137.5385\n",
            "Epoch 179/500\n",
            "70/70 [==============================] - 0s 314us/sample - loss: 117.6701 - val_loss: 137.4248\n",
            "Epoch 180/500\n",
            "70/70 [==============================] - 0s 327us/sample - loss: 117.5421 - val_loss: 137.2990\n",
            "Epoch 181/500\n",
            "70/70 [==============================] - 0s 323us/sample - loss: 117.3988 - val_loss: 137.1612\n",
            "Epoch 182/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 117.2546 - val_loss: 137.0095\n",
            "Epoch 183/500\n",
            "70/70 [==============================] - 0s 337us/sample - loss: 117.0829 - val_loss: 136.8487\n",
            "Epoch 184/500\n",
            "70/70 [==============================] - 0s 429us/sample - loss: 116.9121 - val_loss: 136.6750\n",
            "Epoch 185/500\n",
            "70/70 [==============================] - 0s 330us/sample - loss: 116.7288 - val_loss: 136.4889\n",
            "Epoch 186/500\n",
            "70/70 [==============================] - 0s 326us/sample - loss: 116.5304 - val_loss: 136.2886\n",
            "Epoch 187/500\n",
            "70/70 [==============================] - 0s 353us/sample - loss: 116.3170 - val_loss: 136.0721\n",
            "Epoch 188/500\n",
            "70/70 [==============================] - 0s 305us/sample - loss: 116.0880 - val_loss: 135.8379\n",
            "Epoch 189/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 115.8300 - val_loss: 135.5796\n",
            "Epoch 190/500\n",
            "70/70 [==============================] - 0s 321us/sample - loss: 115.5587 - val_loss: 135.2845\n",
            "Epoch 191/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 115.2389 - val_loss: 134.9514\n",
            "Epoch 192/500\n",
            "70/70 [==============================] - 0s 357us/sample - loss: 114.8928 - val_loss: 134.5761\n",
            "Epoch 193/500\n",
            "70/70 [==============================] - 0s 389us/sample - loss: 114.5108 - val_loss: 134.1651\n",
            "Epoch 194/500\n",
            "70/70 [==============================] - 0s 363us/sample - loss: 114.0827 - val_loss: 133.7177\n",
            "Epoch 195/500\n",
            "70/70 [==============================] - 0s 354us/sample - loss: 113.6143 - val_loss: 133.2238\n",
            "Epoch 196/500\n",
            "70/70 [==============================] - 0s 313us/sample - loss: 113.1060 - val_loss: 132.6666\n",
            "Epoch 197/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 112.5154 - val_loss: 132.0412\n",
            "Epoch 198/500\n",
            "70/70 [==============================] - 0s 407us/sample - loss: 111.8843 - val_loss: 131.3300\n",
            "Epoch 199/500\n",
            "70/70 [==============================] - 0s 299us/sample - loss: 111.1550 - val_loss: 130.5327\n",
            "Epoch 200/500\n",
            "70/70 [==============================] - 0s 286us/sample - loss: 110.3509 - val_loss: 129.6303\n",
            "Epoch 201/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 109.4400 - val_loss: 128.5987\n",
            "Epoch 202/500\n",
            "70/70 [==============================] - 0s 318us/sample - loss: 108.3769 - val_loss: 127.4138\n",
            "Epoch 203/500\n",
            "70/70 [==============================] - 0s 388us/sample - loss: 107.1914 - val_loss: 126.0419\n",
            "Epoch 204/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 105.8148 - val_loss: 124.4627\n",
            "Epoch 205/500\n",
            "70/70 [==============================] - 0s 370us/sample - loss: 104.2447 - val_loss: 122.6608\n",
            "Epoch 206/500\n",
            "70/70 [==============================] - 0s 335us/sample - loss: 102.4739 - val_loss: 120.6057\n",
            "Epoch 207/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 100.4167 - val_loss: 118.2354\n",
            "Epoch 208/500\n",
            "70/70 [==============================] - 0s 322us/sample - loss: 98.0427 - val_loss: 115.4781\n",
            "Epoch 209/500\n",
            "70/70 [==============================] - 0s 323us/sample - loss: 95.3435 - val_loss: 112.2836\n",
            "Epoch 210/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 92.0989 - val_loss: 108.6428\n",
            "Epoch 211/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 88.4164 - val_loss: 104.4430\n",
            "Epoch 212/500\n",
            "70/70 [==============================] - 0s 347us/sample - loss: 84.2000 - val_loss: 99.6617\n",
            "Epoch 213/500\n",
            "70/70 [==============================] - 0s 427us/sample - loss: 79.1205 - val_loss: 94.2382\n",
            "Epoch 214/500\n",
            "70/70 [==============================] - 0s 409us/sample - loss: 73.0332 - val_loss: 87.9334\n",
            "Epoch 215/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 66.7078 - val_loss: 80.5614\n",
            "Epoch 216/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 58.0178 - val_loss: 71.7781\n",
            "Epoch 217/500\n",
            "70/70 [==============================] - 0s 283us/sample - loss: 49.8688 - val_loss: 61.0277\n",
            "Epoch 218/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 39.5322 - val_loss: 48.7800\n",
            "Epoch 219/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 27.7454 - val_loss: 34.9283\n",
            "Epoch 220/500\n",
            "70/70 [==============================] - 0s 344us/sample - loss: 19.7571 - val_loss: 21.6765\n",
            "Epoch 221/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 12.3666 - val_loss: 14.0139\n",
            "Epoch 222/500\n",
            "70/70 [==============================] - 0s 409us/sample - loss: 11.6010 - val_loss: 12.1526\n",
            "Epoch 223/500\n",
            "70/70 [==============================] - 0s 435us/sample - loss: 12.2858 - val_loss: 11.8741\n",
            "Epoch 224/500\n",
            "70/70 [==============================] - 0s 324us/sample - loss: 12.2444 - val_loss: 10.9528\n",
            "Epoch 225/500\n",
            "70/70 [==============================] - 0s 385us/sample - loss: 11.1691 - val_loss: 9.4784\n",
            "Epoch 226/500\n",
            "70/70 [==============================] - 0s 346us/sample - loss: 9.4627 - val_loss: 7.9987\n",
            "Epoch 227/500\n",
            "70/70 [==============================] - 0s 307us/sample - loss: 7.7584 - val_loss: 6.9589\n",
            "Epoch 228/500\n",
            "70/70 [==============================] - 0s 324us/sample - loss: 6.3768 - val_loss: 6.4220\n",
            "Epoch 229/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 5.4028 - val_loss: 6.2748\n",
            "Epoch 230/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 4.9806 - val_loss: 6.3266\n",
            "Epoch 231/500\n",
            "70/70 [==============================] - 0s 353us/sample - loss: 4.5519 - val_loss: 6.1913\n",
            "Epoch 232/500\n",
            "70/70 [==============================] - 0s 368us/sample - loss: 4.2656 - val_loss: 5.9779\n",
            "Epoch 233/500\n",
            "70/70 [==============================] - 0s 383us/sample - loss: 4.0078 - val_loss: 5.6504\n",
            "Epoch 234/500\n",
            "70/70 [==============================] - 0s 327us/sample - loss: 3.7601 - val_loss: 5.2772\n",
            "Epoch 235/500\n",
            "70/70 [==============================] - 0s 314us/sample - loss: 3.4999 - val_loss: 4.8059\n",
            "Epoch 236/500\n",
            "70/70 [==============================] - 0s 298us/sample - loss: 3.2793 - val_loss: 4.3337\n",
            "Epoch 237/500\n",
            "70/70 [==============================] - 0s 303us/sample - loss: 3.0006 - val_loss: 3.9881\n",
            "Epoch 238/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 2.8083 - val_loss: 3.7032\n",
            "Epoch 239/500\n",
            "70/70 [==============================] - 0s 381us/sample - loss: 2.6366 - val_loss: 3.4428\n",
            "Epoch 240/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 2.4776 - val_loss: 3.1644\n",
            "Epoch 241/500\n",
            "70/70 [==============================] - 0s 355us/sample - loss: 2.3204 - val_loss: 2.9099\n",
            "Epoch 242/500\n",
            "70/70 [==============================] - 0s 436us/sample - loss: 2.2145 - val_loss: 2.6856\n",
            "Epoch 243/500\n",
            "70/70 [==============================] - 0s 392us/sample - loss: 2.1101 - val_loss: 2.5137\n",
            "Epoch 244/500\n",
            "70/70 [==============================] - 0s 368us/sample - loss: 2.0282 - val_loss: 2.3733\n",
            "Epoch 245/500\n",
            "70/70 [==============================] - 0s 365us/sample - loss: 1.9438 - val_loss: 2.2619\n",
            "Epoch 246/500\n",
            "70/70 [==============================] - 0s 417us/sample - loss: 1.8439 - val_loss: 2.1672\n",
            "Epoch 247/500\n",
            "70/70 [==============================] - 0s 336us/sample - loss: 1.7441 - val_loss: 2.0833\n",
            "Epoch 248/500\n",
            "70/70 [==============================] - 0s 363us/sample - loss: 1.6514 - val_loss: 2.0186\n",
            "Epoch 249/500\n",
            "70/70 [==============================] - 0s 395us/sample - loss: 1.5636 - val_loss: 1.9688\n",
            "Epoch 250/500\n",
            "70/70 [==============================] - 0s 349us/sample - loss: 1.4808 - val_loss: 1.9280\n",
            "Epoch 251/500\n",
            "70/70 [==============================] - 0s 333us/sample - loss: 1.4148 - val_loss: 1.9046\n",
            "Epoch 252/500\n",
            "70/70 [==============================] - 0s 392us/sample - loss: 1.3602 - val_loss: 1.8889\n",
            "Epoch 253/500\n",
            "70/70 [==============================] - 0s 304us/sample - loss: 1.3089 - val_loss: 1.8654\n",
            "Epoch 254/500\n",
            "70/70 [==============================] - 0s 334us/sample - loss: 1.2659 - val_loss: 1.8417\n",
            "Epoch 255/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 1.2294 - val_loss: 1.7995\n",
            "Epoch 256/500\n",
            "70/70 [==============================] - 0s 364us/sample - loss: 1.1830 - val_loss: 1.7187\n",
            "Epoch 257/500\n",
            "70/70 [==============================] - 0s 339us/sample - loss: 1.1409 - val_loss: 1.6252\n",
            "Epoch 258/500\n",
            "70/70 [==============================] - 0s 378us/sample - loss: 1.0918 - val_loss: 1.5518\n",
            "Epoch 259/500\n",
            "70/70 [==============================] - 0s 350us/sample - loss: 1.0486 - val_loss: 1.4848\n",
            "Epoch 260/500\n",
            "70/70 [==============================] - 0s 368us/sample - loss: 1.0143 - val_loss: 1.4159\n",
            "Epoch 261/500\n",
            "70/70 [==============================] - 0s 357us/sample - loss: 0.9775 - val_loss: 1.3553\n",
            "Epoch 262/500\n",
            "70/70 [==============================] - 0s 389us/sample - loss: 0.9487 - val_loss: 1.2941\n",
            "Epoch 263/500\n",
            "70/70 [==============================] - 0s 364us/sample - loss: 0.9207 - val_loss: 1.2445\n",
            "Epoch 264/500\n",
            "70/70 [==============================] - 0s 317us/sample - loss: 0.8941 - val_loss: 1.2006\n",
            "Epoch 265/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 0.8669 - val_loss: 1.1620\n",
            "Epoch 266/500\n",
            "70/70 [==============================] - 0s 292us/sample - loss: 0.8406 - val_loss: 1.1270\n",
            "Epoch 267/500\n",
            "70/70 [==============================] - 0s 324us/sample - loss: 0.8159 - val_loss: 1.1018\n",
            "Epoch 268/500\n",
            "70/70 [==============================] - 0s 302us/sample - loss: 0.7925 - val_loss: 1.0813\n",
            "Epoch 269/500\n",
            "70/70 [==============================] - 0s 361us/sample - loss: 0.7669 - val_loss: 1.0546\n",
            "Epoch 270/500\n",
            "70/70 [==============================] - 0s 354us/sample - loss: 0.7454 - val_loss: 1.0316\n",
            "Epoch 271/500\n",
            "70/70 [==============================] - 0s 423us/sample - loss: 0.7266 - val_loss: 1.0128\n",
            "Epoch 272/500\n",
            "70/70 [==============================] - 0s 418us/sample - loss: 0.7064 - val_loss: 0.9927\n",
            "Epoch 273/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 0.6890 - val_loss: 0.9756\n",
            "Epoch 274/500\n",
            "70/70 [==============================] - 0s 283us/sample - loss: 0.6725 - val_loss: 0.9607\n",
            "Epoch 275/500\n",
            "70/70 [==============================] - 0s 298us/sample - loss: 0.6561 - val_loss: 0.9471\n",
            "Epoch 276/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 0.6415 - val_loss: 0.9349\n",
            "Epoch 277/500\n",
            "70/70 [==============================] - 0s 382us/sample - loss: 0.6288 - val_loss: 0.9193\n",
            "Epoch 278/500\n",
            "70/70 [==============================] - 0s 338us/sample - loss: 0.6134 - val_loss: 0.8927\n",
            "Epoch 279/500\n",
            "70/70 [==============================] - 0s 346us/sample - loss: 0.5989 - val_loss: 0.8692\n",
            "Epoch 280/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.5861 - val_loss: 0.8487\n",
            "Epoch 281/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 0.5717 - val_loss: 0.8303\n",
            "Epoch 282/500\n",
            "70/70 [==============================] - 0s 349us/sample - loss: 0.5596 - val_loss: 0.8040\n",
            "Epoch 283/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 0.5467 - val_loss: 0.7798\n",
            "Epoch 284/500\n",
            "70/70 [==============================] - 0s 320us/sample - loss: 0.5352 - val_loss: 0.7584\n",
            "Epoch 285/500\n",
            "70/70 [==============================] - 0s 335us/sample - loss: 0.5235 - val_loss: 0.7376\n",
            "Epoch 286/500\n",
            "70/70 [==============================] - 0s 359us/sample - loss: 0.5136 - val_loss: 0.7158\n",
            "Epoch 287/500\n",
            "70/70 [==============================] - 0s 322us/sample - loss: 0.5036 - val_loss: 0.6993\n",
            "Epoch 288/500\n",
            "70/70 [==============================] - 0s 362us/sample - loss: 0.4936 - val_loss: 0.6860\n",
            "Epoch 289/500\n",
            "70/70 [==============================] - 0s 372us/sample - loss: 0.4849 - val_loss: 0.6746\n",
            "Epoch 290/500\n",
            "70/70 [==============================] - 0s 363us/sample - loss: 0.4747 - val_loss: 0.6649\n",
            "Epoch 291/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 0.4656 - val_loss: 0.6545\n",
            "Epoch 292/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 0.4565 - val_loss: 0.6471\n",
            "Epoch 293/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.4474 - val_loss: 0.6410\n",
            "Epoch 294/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.4394 - val_loss: 0.6338\n",
            "Epoch 295/500\n",
            "70/70 [==============================] - 0s 363us/sample - loss: 0.4307 - val_loss: 0.6195\n",
            "Epoch 296/500\n",
            "70/70 [==============================] - 0s 351us/sample - loss: 0.4231 - val_loss: 0.6026\n",
            "Epoch 297/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 0.4146 - val_loss: 0.5875\n",
            "Epoch 298/500\n",
            "70/70 [==============================] - 0s 509us/sample - loss: 0.4065 - val_loss: 0.5696\n",
            "Epoch 299/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.4011 - val_loss: 0.5527\n",
            "Epoch 300/500\n",
            "70/70 [==============================] - 0s 364us/sample - loss: 0.3942 - val_loss: 0.5394\n",
            "Epoch 301/500\n",
            "70/70 [==============================] - 0s 304us/sample - loss: 0.3874 - val_loss: 0.5269\n",
            "Epoch 302/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 0.3818 - val_loss: 0.5131\n",
            "Epoch 303/500\n",
            "70/70 [==============================] - 0s 277us/sample - loss: 0.3778 - val_loss: 0.5019\n",
            "Epoch 304/500\n",
            "70/70 [==============================] - 0s 360us/sample - loss: 0.3707 - val_loss: 0.4930\n",
            "Epoch 305/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.3640 - val_loss: 0.4838\n",
            "Epoch 306/500\n",
            "70/70 [==============================] - 0s 325us/sample - loss: 0.3577 - val_loss: 0.4743\n",
            "Epoch 307/500\n",
            "70/70 [==============================] - 0s 344us/sample - loss: 0.3517 - val_loss: 0.4666\n",
            "Epoch 308/500\n",
            "70/70 [==============================] - 0s 293us/sample - loss: 0.3448 - val_loss: 0.4615\n",
            "Epoch 309/500\n",
            "70/70 [==============================] - 0s 304us/sample - loss: 0.3381 - val_loss: 0.4580\n",
            "Epoch 310/500\n",
            "70/70 [==============================] - 0s 386us/sample - loss: 0.3315 - val_loss: 0.4549\n",
            "Epoch 311/500\n",
            "70/70 [==============================] - 0s 355us/sample - loss: 0.3264 - val_loss: 0.4537\n",
            "Epoch 312/500\n",
            "70/70 [==============================] - 0s 348us/sample - loss: 0.3197 - val_loss: 0.4515\n",
            "Epoch 313/500\n",
            "70/70 [==============================] - 0s 307us/sample - loss: 0.3147 - val_loss: 0.4498\n",
            "Epoch 314/500\n",
            "70/70 [==============================] - 0s 285us/sample - loss: 0.3115 - val_loss: 0.4480\n",
            "Epoch 315/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.3065 - val_loss: 0.4415\n",
            "Epoch 316/500\n",
            "70/70 [==============================] - 0s 361us/sample - loss: 0.3017 - val_loss: 0.4357\n",
            "Epoch 317/500\n",
            "70/70 [==============================] - 0s 255us/sample - loss: 0.2976 - val_loss: 0.4277\n",
            "Epoch 318/500\n",
            "70/70 [==============================] - 0s 301us/sample - loss: 0.2926 - val_loss: 0.4214\n",
            "Epoch 319/500\n",
            "70/70 [==============================] - 0s 296us/sample - loss: 0.2882 - val_loss: 0.4139\n",
            "Epoch 320/500\n",
            "70/70 [==============================] - 0s 331us/sample - loss: 0.2843 - val_loss: 0.4048\n",
            "Epoch 321/500\n",
            "70/70 [==============================] - 0s 281us/sample - loss: 0.2804 - val_loss: 0.3940\n",
            "Epoch 322/500\n",
            "70/70 [==============================] - 0s 282us/sample - loss: 0.2773 - val_loss: 0.3847\n",
            "Epoch 323/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 0.2734 - val_loss: 0.3777\n",
            "Epoch 324/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 0.2696 - val_loss: 0.3732\n",
            "Epoch 325/500\n",
            "70/70 [==============================] - 0s 293us/sample - loss: 0.2661 - val_loss: 0.3688\n",
            "Epoch 326/500\n",
            "70/70 [==============================] - 0s 362us/sample - loss: 0.2630 - val_loss: 0.3624\n",
            "Epoch 327/500\n",
            "70/70 [==============================] - 0s 337us/sample - loss: 0.2592 - val_loss: 0.3580\n",
            "Epoch 328/500\n",
            "70/70 [==============================] - 0s 287us/sample - loss: 0.2558 - val_loss: 0.3537\n",
            "Epoch 329/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 0.2521 - val_loss: 0.3503\n",
            "Epoch 330/500\n",
            "70/70 [==============================] - 0s 379us/sample - loss: 0.2488 - val_loss: 0.3466\n",
            "Epoch 331/500\n",
            "70/70 [==============================] - 0s 372us/sample - loss: 0.2459 - val_loss: 0.3448\n",
            "Epoch 332/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 0.2432 - val_loss: 0.3436\n",
            "Epoch 333/500\n",
            "70/70 [==============================] - 0s 299us/sample - loss: 0.2402 - val_loss: 0.3415\n",
            "Epoch 334/500\n",
            "70/70 [==============================] - 0s 331us/sample - loss: 0.2374 - val_loss: 0.3401\n",
            "Epoch 335/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.2351 - val_loss: 0.3394\n",
            "Epoch 336/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 0.2333 - val_loss: 0.3369\n",
            "Epoch 337/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 0.2305 - val_loss: 0.3296\n",
            "Epoch 338/500\n",
            "70/70 [==============================] - 0s 279us/sample - loss: 0.2271 - val_loss: 0.3226\n",
            "Epoch 339/500\n",
            "70/70 [==============================] - 0s 313us/sample - loss: 0.2238 - val_loss: 0.3140\n",
            "Epoch 340/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 0.2215 - val_loss: 0.3038\n",
            "Epoch 341/500\n",
            "70/70 [==============================] - 0s 322us/sample - loss: 0.2181 - val_loss: 0.2952\n",
            "Epoch 342/500\n",
            "70/70 [==============================] - 0s 333us/sample - loss: 0.2155 - val_loss: 0.2896\n",
            "Epoch 343/500\n",
            "70/70 [==============================] - 0s 286us/sample - loss: 0.2131 - val_loss: 0.2858\n",
            "Epoch 344/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 0.2109 - val_loss: 0.2825\n",
            "Epoch 345/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 0.2083 - val_loss: 0.2788\n",
            "Epoch 346/500\n",
            "70/70 [==============================] - 0s 266us/sample - loss: 0.2062 - val_loss: 0.2755\n",
            "Epoch 347/500\n",
            "70/70 [==============================] - 0s 268us/sample - loss: 0.2042 - val_loss: 0.2724\n",
            "Epoch 348/500\n",
            "70/70 [==============================] - 0s 280us/sample - loss: 0.2019 - val_loss: 0.2693\n",
            "Epoch 349/500\n",
            "70/70 [==============================] - 0s 318us/sample - loss: 0.2000 - val_loss: 0.2665\n",
            "Epoch 350/500\n",
            "70/70 [==============================] - 0s 468us/sample - loss: 0.1976 - val_loss: 0.2659\n",
            "Epoch 351/500\n",
            "70/70 [==============================] - 0s 281us/sample - loss: 0.1955 - val_loss: 0.2661\n",
            "Epoch 352/500\n",
            "70/70 [==============================] - 0s 347us/sample - loss: 0.1934 - val_loss: 0.2671\n",
            "Epoch 353/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.1923 - val_loss: 0.2688\n",
            "Epoch 354/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 0.1909 - val_loss: 0.2685\n",
            "Epoch 355/500\n",
            "70/70 [==============================] - 0s 330us/sample - loss: 0.1892 - val_loss: 0.2655\n",
            "Epoch 356/500\n",
            "70/70 [==============================] - 0s 372us/sample - loss: 0.1875 - val_loss: 0.2629\n",
            "Epoch 357/500\n",
            "70/70 [==============================] - 0s 295us/sample - loss: 0.1855 - val_loss: 0.2590\n",
            "Epoch 358/500\n",
            "70/70 [==============================] - 0s 280us/sample - loss: 0.1835 - val_loss: 0.2549\n",
            "Epoch 359/500\n",
            "70/70 [==============================] - 0s 275us/sample - loss: 0.1817 - val_loss: 0.2499\n",
            "Epoch 360/500\n",
            "70/70 [==============================] - 0s 335us/sample - loss: 0.1796 - val_loss: 0.2434\n",
            "Epoch 361/500\n",
            "70/70 [==============================] - 0s 282us/sample - loss: 0.1778 - val_loss: 0.2387\n",
            "Epoch 362/500\n",
            "70/70 [==============================] - 0s 286us/sample - loss: 0.1759 - val_loss: 0.2349\n",
            "Epoch 363/500\n",
            "70/70 [==============================] - 0s 319us/sample - loss: 0.1742 - val_loss: 0.2297\n",
            "Epoch 364/500\n",
            "70/70 [==============================] - 0s 370us/sample - loss: 0.1726 - val_loss: 0.2232\n",
            "Epoch 365/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 0.1718 - val_loss: 0.2178\n",
            "Epoch 366/500\n",
            "70/70 [==============================] - 0s 280us/sample - loss: 0.1702 - val_loss: 0.2141\n",
            "Epoch 367/500\n",
            "70/70 [==============================] - 0s 270us/sample - loss: 0.1693 - val_loss: 0.2115\n",
            "Epoch 368/500\n",
            "70/70 [==============================] - 0s 265us/sample - loss: 0.1678 - val_loss: 0.2104\n",
            "Epoch 369/500\n",
            "70/70 [==============================] - 0s 261us/sample - loss: 0.1661 - val_loss: 0.2096\n",
            "Epoch 370/500\n",
            "70/70 [==============================] - 0s 266us/sample - loss: 0.1644 - val_loss: 0.2088\n",
            "Epoch 371/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 0.1627 - val_loss: 0.2087\n",
            "Epoch 372/500\n",
            "70/70 [==============================] - 0s 319us/sample - loss: 0.1611 - val_loss: 0.2088\n",
            "Epoch 373/500\n",
            "70/70 [==============================] - 0s 402us/sample - loss: 0.1600 - val_loss: 0.2089\n",
            "Epoch 374/500\n",
            "70/70 [==============================] - 0s 329us/sample - loss: 0.1587 - val_loss: 0.2070\n",
            "Epoch 375/500\n",
            "70/70 [==============================] - 0s 301us/sample - loss: 0.1567 - val_loss: 0.2020\n",
            "Epoch 376/500\n",
            "70/70 [==============================] - 0s 323us/sample - loss: 0.1554 - val_loss: 0.1962\n",
            "Epoch 377/500\n",
            "70/70 [==============================] - 0s 298us/sample - loss: 0.1541 - val_loss: 0.1917\n",
            "Epoch 378/500\n",
            "70/70 [==============================] - 0s 364us/sample - loss: 0.1532 - val_loss: 0.1878\n",
            "Epoch 379/500\n",
            "70/70 [==============================] - 0s 288us/sample - loss: 0.1523 - val_loss: 0.1850\n",
            "Epoch 380/500\n",
            "70/70 [==============================] - 0s 279us/sample - loss: 0.1512 - val_loss: 0.1828\n",
            "Epoch 381/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.1500 - val_loss: 0.1814\n",
            "Epoch 382/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 0.1488 - val_loss: 0.1804\n",
            "Epoch 383/500\n",
            "70/70 [==============================] - 0s 321us/sample - loss: 0.1473 - val_loss: 0.1787\n",
            "Epoch 384/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 0.1458 - val_loss: 0.1777\n",
            "Epoch 385/500\n",
            "70/70 [==============================] - 0s 362us/sample - loss: 0.1444 - val_loss: 0.1771\n",
            "Epoch 386/500\n",
            "70/70 [==============================] - 0s 410us/sample - loss: 0.1431 - val_loss: 0.1765\n",
            "Epoch 387/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 0.1418 - val_loss: 0.1744\n",
            "Epoch 388/500\n",
            "70/70 [==============================] - 0s 324us/sample - loss: 0.1406 - val_loss: 0.1712\n",
            "Epoch 389/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 0.1395 - val_loss: 0.1696\n",
            "Epoch 390/500\n",
            "70/70 [==============================] - 0s 254us/sample - loss: 0.1383 - val_loss: 0.1686\n",
            "Epoch 391/500\n",
            "70/70 [==============================] - 0s 431us/sample - loss: 0.1371 - val_loss: 0.1670\n",
            "Epoch 392/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 0.1360 - val_loss: 0.1645\n",
            "Epoch 393/500\n",
            "70/70 [==============================] - 0s 321us/sample - loss: 0.1349 - val_loss: 0.1627\n",
            "Epoch 394/500\n",
            "70/70 [==============================] - 0s 347us/sample - loss: 0.1338 - val_loss: 0.1612\n",
            "Epoch 395/500\n",
            "70/70 [==============================] - 0s 336us/sample - loss: 0.1329 - val_loss: 0.1595\n",
            "Epoch 396/500\n",
            "70/70 [==============================] - 0s 289us/sample - loss: 0.1322 - val_loss: 0.1566\n",
            "Epoch 397/500\n",
            "70/70 [==============================] - 0s 347us/sample - loss: 0.1312 - val_loss: 0.1546\n",
            "Epoch 398/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 0.1304 - val_loss: 0.1526\n",
            "Epoch 399/500\n",
            "70/70 [==============================] - 0s 331us/sample - loss: 0.1297 - val_loss: 0.1505\n",
            "Epoch 400/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 0.1289 - val_loss: 0.1489\n",
            "Epoch 401/500\n",
            "70/70 [==============================] - 0s 371us/sample - loss: 0.1280 - val_loss: 0.1469\n",
            "Epoch 402/500\n",
            "70/70 [==============================] - 0s 361us/sample - loss: 0.1273 - val_loss: 0.1455\n",
            "Epoch 403/500\n",
            "70/70 [==============================] - 0s 388us/sample - loss: 0.1265 - val_loss: 0.1449\n",
            "Epoch 404/500\n",
            "70/70 [==============================] - 0s 299us/sample - loss: 0.1253 - val_loss: 0.1447\n",
            "Epoch 405/500\n",
            "70/70 [==============================] - 0s 299us/sample - loss: 0.1241 - val_loss: 0.1447\n",
            "Epoch 406/500\n",
            "70/70 [==============================] - 0s 342us/sample - loss: 0.1230 - val_loss: 0.1452\n",
            "Epoch 407/500\n",
            "70/70 [==============================] - 0s 314us/sample - loss: 0.1224 - val_loss: 0.1463\n",
            "Epoch 408/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 0.1213 - val_loss: 0.1474\n",
            "Epoch 409/500\n",
            "70/70 [==============================] - 0s 333us/sample - loss: 0.1203 - val_loss: 0.1485\n",
            "Epoch 410/500\n",
            "70/70 [==============================] - 0s 296us/sample - loss: 0.1200 - val_loss: 0.1492\n",
            "Epoch 411/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.1196 - val_loss: 0.1486\n",
            "Epoch 412/500\n",
            "70/70 [==============================] - 0s 281us/sample - loss: 0.1189 - val_loss: 0.1470\n",
            "Epoch 413/500\n",
            "70/70 [==============================] - 0s 305us/sample - loss: 0.1182 - val_loss: 0.1451\n",
            "Epoch 414/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.1175 - val_loss: 0.1436\n",
            "Epoch 415/500\n",
            "70/70 [==============================] - 0s 350us/sample - loss: 0.1167 - val_loss: 0.1425\n",
            "Epoch 416/500\n",
            "70/70 [==============================] - 0s 296us/sample - loss: 0.1161 - val_loss: 0.1417\n",
            "Epoch 417/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 0.1156 - val_loss: 0.1413\n",
            "Epoch 418/500\n",
            "70/70 [==============================] - 0s 277us/sample - loss: 0.1150 - val_loss: 0.1407\n",
            "Epoch 419/500\n",
            "70/70 [==============================] - 0s 352us/sample - loss: 0.1144 - val_loss: 0.1401\n",
            "Epoch 420/500\n",
            "70/70 [==============================] - 0s 304us/sample - loss: 0.1139 - val_loss: 0.1390\n",
            "Epoch 421/500\n",
            "70/70 [==============================] - 0s 344us/sample - loss: 0.1133 - val_loss: 0.1371\n",
            "Epoch 422/500\n",
            "70/70 [==============================] - 0s 300us/sample - loss: 0.1127 - val_loss: 0.1356\n",
            "Epoch 423/500\n",
            "70/70 [==============================] - 0s 304us/sample - loss: 0.1120 - val_loss: 0.1347\n",
            "Epoch 424/500\n",
            "70/70 [==============================] - 0s 386us/sample - loss: 0.1114 - val_loss: 0.1340\n",
            "Epoch 425/500\n",
            "70/70 [==============================] - 0s 305us/sample - loss: 0.1109 - val_loss: 0.1329\n",
            "Epoch 426/500\n",
            "70/70 [==============================] - 0s 299us/sample - loss: 0.1102 - val_loss: 0.1312\n",
            "Epoch 427/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 0.1096 - val_loss: 0.1292\n",
            "Epoch 428/500\n",
            "70/70 [==============================] - 0s 291us/sample - loss: 0.1092 - val_loss: 0.1276\n",
            "Epoch 429/500\n",
            "70/70 [==============================] - 0s 283us/sample - loss: 0.1085 - val_loss: 0.1269\n",
            "Epoch 430/500\n",
            "70/70 [==============================] - 0s 386us/sample - loss: 0.1080 - val_loss: 0.1267\n",
            "Epoch 431/500\n",
            "70/70 [==============================] - 0s 350us/sample - loss: 0.1075 - val_loss: 0.1260\n",
            "Epoch 432/500\n",
            "70/70 [==============================] - 0s 339us/sample - loss: 0.1070 - val_loss: 0.1255\n",
            "Epoch 433/500\n",
            "70/70 [==============================] - 0s 331us/sample - loss: 0.1066 - val_loss: 0.1240\n",
            "Epoch 434/500\n",
            "70/70 [==============================] - 0s 341us/sample - loss: 0.1059 - val_loss: 0.1230\n",
            "Epoch 435/500\n",
            "70/70 [==============================] - 0s 320us/sample - loss: 0.1054 - val_loss: 0.1221\n",
            "Epoch 436/500\n",
            "70/70 [==============================] - 0s 354us/sample - loss: 0.1049 - val_loss: 0.1209\n",
            "Epoch 437/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 0.1043 - val_loss: 0.1201\n",
            "Epoch 438/500\n",
            "70/70 [==============================] - 0s 302us/sample - loss: 0.1038 - val_loss: 0.1197\n",
            "Epoch 439/500\n",
            "70/70 [==============================] - 0s 332us/sample - loss: 0.1034 - val_loss: 0.1197\n",
            "Epoch 440/500\n",
            "70/70 [==============================] - 0s 289us/sample - loss: 0.1029 - val_loss: 0.1201\n",
            "Epoch 441/500\n",
            "70/70 [==============================] - 0s 269us/sample - loss: 0.1028 - val_loss: 0.1209\n",
            "Epoch 442/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 0.1024 - val_loss: 0.1214\n",
            "Epoch 443/500\n",
            "70/70 [==============================] - 0s 333us/sample - loss: 0.1021 - val_loss: 0.1215\n",
            "Epoch 444/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 0.1018 - val_loss: 0.1206\n",
            "Epoch 445/500\n",
            "70/70 [==============================] - 0s 310us/sample - loss: 0.1015 - val_loss: 0.1187\n",
            "Epoch 446/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 0.1008 - val_loss: 0.1173\n",
            "Epoch 447/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.1002 - val_loss: 0.1164\n",
            "Epoch 448/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 0.0998 - val_loss: 0.1157\n",
            "Epoch 449/500\n",
            "70/70 [==============================] - 0s 295us/sample - loss: 0.0994 - val_loss: 0.1151\n",
            "Epoch 450/500\n",
            "70/70 [==============================] - 0s 400us/sample - loss: 0.0988 - val_loss: 0.1134\n",
            "Epoch 451/500\n",
            "70/70 [==============================] - 0s 360us/sample - loss: 0.0982 - val_loss: 0.1116\n",
            "Epoch 452/500\n",
            "70/70 [==============================] - 0s 306us/sample - loss: 0.0977 - val_loss: 0.1094\n",
            "Epoch 453/500\n",
            "70/70 [==============================] - 0s 273us/sample - loss: 0.0972 - val_loss: 0.1077\n",
            "Epoch 454/500\n",
            "70/70 [==============================] - 0s 293us/sample - loss: 0.0969 - val_loss: 0.1062\n",
            "Epoch 455/500\n",
            "70/70 [==============================] - 0s 296us/sample - loss: 0.0964 - val_loss: 0.1054\n",
            "Epoch 456/500\n",
            "70/70 [==============================] - 0s 297us/sample - loss: 0.0960 - val_loss: 0.1049\n",
            "Epoch 457/500\n",
            "70/70 [==============================] - 0s 281us/sample - loss: 0.0956 - val_loss: 0.1044\n",
            "Epoch 458/500\n",
            "70/70 [==============================] - 0s 375us/sample - loss: 0.0952 - val_loss: 0.1038\n",
            "Epoch 459/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 0.0948 - val_loss: 0.1033\n",
            "Epoch 460/500\n",
            "70/70 [==============================] - 0s 350us/sample - loss: 0.0944 - val_loss: 0.1025\n",
            "Epoch 461/500\n",
            "70/70 [==============================] - 0s 325us/sample - loss: 0.0939 - val_loss: 0.1025\n",
            "Epoch 462/500\n",
            "70/70 [==============================] - 0s 328us/sample - loss: 0.0935 - val_loss: 0.1027\n",
            "Epoch 463/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 0.0932 - val_loss: 0.1027\n",
            "Epoch 464/500\n",
            "70/70 [==============================] - 0s 291us/sample - loss: 0.0928 - val_loss: 0.1017\n",
            "Epoch 465/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 0.0923 - val_loss: 0.1009\n",
            "Epoch 466/500\n",
            "70/70 [==============================] - 0s 302us/sample - loss: 0.0919 - val_loss: 0.1002\n",
            "Epoch 467/500\n",
            "70/70 [==============================] - 0s 340us/sample - loss: 0.0915 - val_loss: 0.0994\n",
            "Epoch 468/500\n",
            "70/70 [==============================] - 0s 317us/sample - loss: 0.0912 - val_loss: 0.0983\n",
            "Epoch 469/500\n",
            "70/70 [==============================] - 0s 325us/sample - loss: 0.0908 - val_loss: 0.0971\n",
            "Epoch 470/500\n",
            "70/70 [==============================] - 0s 318us/sample - loss: 0.0905 - val_loss: 0.0962\n",
            "Epoch 471/500\n",
            "70/70 [==============================] - 0s 373us/sample - loss: 0.0902 - val_loss: 0.0952\n",
            "Epoch 472/500\n",
            "70/70 [==============================] - 0s 343us/sample - loss: 0.0899 - val_loss: 0.0947\n",
            "Epoch 473/500\n",
            "70/70 [==============================] - 0s 311us/sample - loss: 0.0896 - val_loss: 0.0942\n",
            "Epoch 474/500\n",
            "70/70 [==============================] - 0s 315us/sample - loss: 0.0892 - val_loss: 0.0935\n",
            "Epoch 475/500\n",
            "70/70 [==============================] - 0s 329us/sample - loss: 0.0889 - val_loss: 0.0930\n",
            "Epoch 476/500\n",
            "70/70 [==============================] - 0s 308us/sample - loss: 0.0886 - val_loss: 0.0922\n",
            "Epoch 477/500\n",
            "70/70 [==============================] - 0s 337us/sample - loss: 0.0882 - val_loss: 0.0919\n",
            "Epoch 478/500\n",
            "70/70 [==============================] - 0s 358us/sample - loss: 0.0879 - val_loss: 0.0919\n",
            "Epoch 479/500\n",
            "70/70 [==============================] - 0s 320us/sample - loss: 0.0875 - val_loss: 0.0919\n",
            "Epoch 480/500\n",
            "70/70 [==============================] - 0s 290us/sample - loss: 0.0873 - val_loss: 0.0918\n",
            "Epoch 481/500\n",
            "70/70 [==============================] - 0s 326us/sample - loss: 0.0870 - val_loss: 0.0918\n",
            "Epoch 482/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 0.0867 - val_loss: 0.0914\n",
            "Epoch 483/500\n",
            "70/70 [==============================] - 0s 324us/sample - loss: 0.0864 - val_loss: 0.0916\n",
            "Epoch 484/500\n",
            "70/70 [==============================] - 0s 329us/sample - loss: 0.0862 - val_loss: 0.0914\n",
            "Epoch 485/500\n",
            "70/70 [==============================] - 0s 318us/sample - loss: 0.0858 - val_loss: 0.0909\n",
            "Epoch 486/500\n",
            "70/70 [==============================] - 0s 549us/sample - loss: 0.0855 - val_loss: 0.0906\n",
            "Epoch 487/500\n",
            "70/70 [==============================] - 0s 334us/sample - loss: 0.0853 - val_loss: 0.0902\n",
            "Epoch 488/500\n",
            "70/70 [==============================] - 0s 377us/sample - loss: 0.0850 - val_loss: 0.0895\n",
            "Epoch 489/500\n",
            "70/70 [==============================] - 0s 316us/sample - loss: 0.0847 - val_loss: 0.0885\n",
            "Epoch 490/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 0.0844 - val_loss: 0.0879\n",
            "Epoch 491/500\n",
            "70/70 [==============================] - 0s 314us/sample - loss: 0.0841 - val_loss: 0.0875\n",
            "Epoch 492/500\n",
            "70/70 [==============================] - 0s 345us/sample - loss: 0.0839 - val_loss: 0.0871\n",
            "Epoch 493/500\n",
            "70/70 [==============================] - 0s 299us/sample - loss: 0.0836 - val_loss: 0.0871\n",
            "Epoch 494/500\n",
            "70/70 [==============================] - 0s 309us/sample - loss: 0.0834 - val_loss: 0.0875\n",
            "Epoch 495/500\n",
            "70/70 [==============================] - 0s 364us/sample - loss: 0.0831 - val_loss: 0.0876\n",
            "Epoch 496/500\n",
            "70/70 [==============================] - 0s 368us/sample - loss: 0.0829 - val_loss: 0.0876\n",
            "Epoch 497/500\n",
            "70/70 [==============================] - 0s 373us/sample - loss: 0.0827 - val_loss: 0.0878\n",
            "Epoch 498/500\n",
            "70/70 [==============================] - 0s 335us/sample - loss: 0.0825 - val_loss: 0.0878\n",
            "Epoch 499/500\n",
            "70/70 [==============================] - 0s 335us/sample - loss: 0.0822 - val_loss: 0.0864\n",
            "Epoch 500/500\n",
            "70/70 [==============================] - 0s 442us/sample - loss: 0.0817 - val_loss: 0.0842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PFdeckLLnQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ye=model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-PkNcmj9sgF",
        "colab_type": "code",
        "outputId": "b84de57c-3dc7-49b9-ba53-0e90c9712d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ye,color='blue')\n",
        "plt.plot(y,color='red')\n",
        "plt.show()\n",
        "\n",
        "print(\"X: \", X[96:], \"\\n\\n\\n YE:\", y[96:])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmGKKKSYUUwKfYooppphQ/P8OeA1BVRT7DQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "X:  [[[3]\n",
            "  [4]\n",
            "  [5]]\n",
            "\n",
            " [[6]\n",
            "  [7]\n",
            "  [8]]\n",
            "\n",
            " [[6]\n",
            "  [7]\n",
            "  [8]]\n",
            "\n",
            " [[4]\n",
            "  [5]\n",
            "  [6]]] \n",
            "\n",
            "\n",
            " YE: [[6]\n",
            " [9]\n",
            " [9]\n",
            " [7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmwSy4FPUV4T",
        "colab_type": "code",
        "outputId": "e4c99a94-b087-44a3-a47e-f63ba38ed7b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "w=model.get_weights()# os pesos vêm na ordem : Pesos do input, Pesos da recorrência e bias\n",
        "w"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.10655083,  1.0022012 ,  0.54018253,  1.2279482 ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.83143854,  1.381299  , -0.1845527 ,  0.23537627]],\n",
              "       dtype=float32),\n",
              " array([0.72938424, 1.3907549 , 0.59400177, 0.42110553], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKNxb5WiVUYf",
        "colab_type": "code",
        "outputId": "2494fec2-3171-46e6-8adb-d5f817363098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(model.layers[0].trainable_weights)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'lstm_3/kernel:0' shape=(1, 4) dtype=float32, numpy=\n",
            "array([[-0.10655083,  1.0022012 ,  0.54018253,  1.2279482 ]],\n",
            "      dtype=float32)>, <tf.Variable 'lstm_3/recurrent_kernel:0' shape=(1, 4) dtype=float32, numpy=\n",
            "array([[ 0.83143854,  1.381299  , -0.1845527 ,  0.23537627]],\n",
            "      dtype=float32)>, <tf.Variable 'lstm_3/bias:0' shape=(4,) dtype=float32, numpy=array([0.72938424, 1.3907549 , 0.59400177, 0.42110553], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnQjp_5nPzrk",
        "colab_type": "text"
      },
      "source": [
        "ifco é a ordem dos pesos em cada um dos 3 conjuntos:\n",
        "input (posição 0),\n",
        "forget (posição 1)\n",
        "content (posição 2)\n",
        "output (posição 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3thJ1f9Hp2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ww,uw,bw=w[0],w[1],w[2]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z26xqW98Kq6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sig(z):\n",
        "  return 1/(1+math.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9qUmltmLgX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tanh(z):\n",
        "  return (math.exp(2*z)-1)/(math.exp(2*z)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmPFYPCbN-rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#função oper: aplica peso U no output anterior (h), W no input atual (x), soma bias e aplica ativação\n",
        "def oper(U,W,B,x,h,activ):\n",
        "  return activ(U*h+W*x+B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXrhaGPrOfMm",
        "colab_type": "code",
        "outputId": "99cec231-71b3-4701-cd4e-58f64a39147f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11],\n",
              "       [12],\n",
              "       [13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNQ0AgRIipmw",
        "colab_type": "text"
      },
      "source": [
        "Inicialmente (tempo 0), o output anterior e a memória são nulas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rjunopsTNcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51fe4cd7-3a2a-4dc0-e8ca-87f598d97b52"
      },
      "source": [
        "#Calcule i (filtro input). Dica use função oper\n",
        "i = oper(uw[0][0], ww[0][0], bw[0], X[0][0], 0, sig)\n",
        "i"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39110378846808774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM9f5N70U5j6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59da0f9d-c122-4745-da01-5067f260e12f"
      },
      "source": [
        "#Calcule f (filtro forget). Dica use função oper\n",
        "f = oper(uw[0][1], ww[0][1], bw[1], X[0][0], 0, sig)\n",
        "f"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999995942616257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJIvzmOAWGT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bdcb6c7-aedf-4c9e-f66c-416b475a2bd6"
      },
      "source": [
        "#Calcule cb (conteúdo novo proposto). Dica use função oper\n",
        "cb = oper(uw[0][2], ww[0][2], bw[2], X[0][0], 0, lambda x: x)\n",
        "cb  "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.53600961])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58KAZaBFWQt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "075d5e61-1149-4833-d7fa-d19ab7d174b2"
      },
      "source": [
        "#Calcule  o (output). Dica use função oper\n",
        "o=oper(uw[0][3], ww[0][3], bw[3], X[0][0], 0, sig)\n",
        "o"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999999106872513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqOy41OeUErW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c75bfbac-d0e5-401e-ea20-517b557b3f33"
      },
      "source": [
        "#Calcule o conteúdo novo (depois de aplicar filtros f e i)\n",
        "cant=0.0\n",
        "c=f*cant+i*cb\n",
        "c"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.55625812])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfmwVnUbXA9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71e180eb-4aa2-438b-ac6c-8026bbc4f3f7"
      },
      "source": [
        "#calcule o output o*c\n",
        "out=o*c\n",
        "out"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.55625584])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojumi1yaYxRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8af4b74f-128a-4cfa-d2b7-dc572e8d28ec"
      },
      "source": [
        "#compare com o output do .predict\n",
        "model.predict(np.array([[X[0,0]]]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.556256]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XypYi0KXpcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38de7fbf-1115-4d9e-b966-04c8bfb880f9"
      },
      "source": [
        "#Agora, atualize cant, o output anterior e o novo input..para calcular o segundo output\n",
        "cant=c\n",
        "inp=X[0][1]\n",
        "oa= out\n",
        "i=oper(uw[0][0],ww[0][0],bw[0],inp,oa,sig)\n",
        "f=oper(uw[0][1],ww[0][1],bw[1],inp,oa,sig)\n",
        "cb=oper(uw[0][2],ww[0][2],bw[2],inp,oa,lambda x:x)\n",
        "o=oper(uw[0][3],ww[0][3],bw[3],inp,oa,sig)\n",
        "c=f*cant+i*cb\n",
        "out=o*c\n",
        "out"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.02906724])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tKNaFEepOG1",
        "colab_type": "code",
        "outputId": "106102fd-29ae-4ae8-c432-9d677b035259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#compare com o output do .predict\n",
        "model.predict(np.array([[X[0,0],X[0,1]]]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.029067]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl79qzzTpqpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "288f511d-eef5-4da6-d655-8bd91d995916"
      },
      "source": [
        "#Agora, atualize cant, o output anterior e o novo input..para calcular o terceiro output\n",
        "cant=c\n",
        "inp= X[0][2]\n",
        "oa= out\n",
        "i=oper(uw[0][0],ww[0][0],bw[0],inp,oa,sig)\n",
        "f=oper(uw[0][1],ww[0][1],bw[1],inp,oa,sig)\n",
        "cb=oper(uw[0][2],ww[0][2],bw[2],inp,oa,lambda x:x)\n",
        "o=oper(uw[0][3],ww[0][3],bw[3],inp,oa,sig)\n",
        "c=f*cant+i*cb\n",
        "out=o*c\n",
        "out"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.14878648])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uarFBNC8p15L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29b4ea8b-88fb-43f8-c153-1e2601bb40c0"
      },
      "source": [
        "#compare com o output do .predict\n",
        "model.predict(np.array([[X[0,0],X[0,1],X[0,2]]]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.148786]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTwiuAdTqXd2",
        "colab_type": "code",
        "outputId": "28ed2357-9675-4195-a51f-fb0704515936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.layers[0].get_config()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': '<lambda>',\n",
              " 'activity_regularizer': None,\n",
              " 'batch_input_shape': (None, None, 1),\n",
              " 'bias_constraint': None,\n",
              " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              " 'bias_regularizer': None,\n",
              " 'dropout': 0.0,\n",
              " 'dtype': 'float32',\n",
              " 'go_backwards': False,\n",
              " 'implementation': 2,\n",
              " 'kernel_constraint': None,\n",
              " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "  'config': {'seed': None}},\n",
              " 'kernel_regularizer': None,\n",
              " 'name': 'lstm_3',\n",
              " 'recurrent_activation': 'sigmoid',\n",
              " 'recurrent_constraint': None,\n",
              " 'recurrent_dropout': 0.0,\n",
              " 'recurrent_initializer': {'class_name': 'Orthogonal',\n",
              "  'config': {'gain': 1.0, 'seed': None}},\n",
              " 'recurrent_regularizer': None,\n",
              " 'return_sequences': False,\n",
              " 'return_state': False,\n",
              " 'stateful': False,\n",
              " 'time_major': False,\n",
              " 'trainable': True,\n",
              " 'unit_forget_bias': True,\n",
              " 'units': 1,\n",
              " 'unroll': False,\n",
              " 'use_bias': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}